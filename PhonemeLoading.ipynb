{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843f1b13",
   "metadata": {},
   "source": [
    "# Load Phoneme Dataset and process it\n",
    "Data is found here: https://www.timeseriesclassification.com/description.php?Dataset=PhonemeSpectra\n",
    "\n",
    "Download data, unzip, and move to a folder in this location: '../Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde2afa2-9471-45ce-948f-9f42ea500ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf55627-a0ee-450d-b15d-b050c6f1dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_single_to_numpy(example):\n",
    "    # where example = train[0][n]\n",
    "    # returns the example reshaped into a numpy array of shape (200, 22)\n",
    "    return example[0].view(dtype=np.float64).reshape((11,217))\n",
    "\n",
    "def convert_label(example):\n",
    "    # where example = train[0][n]\n",
    "    # returns the example label decoded into a native string\n",
    "    return example[1].decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99091ecb-c260-45e9-96a6-9b988ff9c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('../Data/Phoneme/test_X.npy')\n",
    "test_labels = np.load('../Data/Phoneme/test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9219b65-1681-4621-ba37-bdae64173f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of split_arr1: (1676, 217, 11)\n",
      "Shape of split_arr2: (1677, 217, 11)\n",
      "Shape of split_arr1: (1676,)\n",
      "Shape of split_arr2: (1677,)\n"
     ]
    }
   ],
   "source": [
    "num_elements = test.shape[0]\n",
    "\n",
    "permuted_indices = np.random.permutation(num_elements)\n",
    "\n",
    "split_arr1 = test[permuted_indices[:num_elements//2], :, :]\n",
    "split_arr2 = test[permuted_indices[num_elements//2:], :, :]\n",
    "\n",
    "split_lab1 = test_labels[permuted_indices[:num_elements//2]]\n",
    "split_lab2 = test_labels[permuted_indices[num_elements//2:]]\n",
    "\n",
    "# Display the shapes of the split arrays\n",
    "print(\"Shape of split_arr1:\", split_arr1.shape)\n",
    "print(\"Shape of split_arr2:\", split_arr2.shape)\n",
    "\n",
    "# Display the shapes of the split arrays\n",
    "print(\"Shape of split_arr1:\", split_lab1.shape)\n",
    "print(\"Shape of split_arr2:\", split_lab2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf9d5ca5-d3cf-49dc-ab41-ae63adf7ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/valid_X.npy', 'wb') as f:\n",
    "    np.save(f, split_arr2)\n",
    "\n",
    "with open('../Data/valid_y.npy', 'wb') as f:\n",
    "    np.save(f, split_lab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b7a647a-9bae-46dd-90f7-c9cd19648fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "data_arrays = []\n",
    "\n",
    "for data_point in train[0]:\n",
    "    data_arrays.append(convert_single_to_numpy(data_point))\n",
    "    labels.append(convert_label(data_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "540b4747-ba4f-400b-bf76-de4656c15ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = np.transpose(np.stack(data_arrays, axis=0), (0, 2, 1))\n",
    "training_labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aefc2b99-546e-477d-9c12-e4b6d9581aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3353, 217, 11)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8c877fa-7b4b-472b-956b-d8d55c48aa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without NaN values: 3353\n"
     ]
    }
   ],
   "source": [
    "no_nan_rows = np.isnan(training_dataset).sum(axis=(1, 2)) == 0\n",
    "num_rows_no_nan = np.count_nonzero(no_nan_rows)\n",
    "print(\"Number of rows without NaN values:\", num_rows_no_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a21a2618-255c-4a67-a18a-40c223ea1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Phoneme/test_X.npy', 'wb') as f:\n",
    "    np.save(f, training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d26f1d9",
   "metadata": {},
   "source": [
    "# Get min and max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6879ef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_train: 126.76\n",
      "max_valid: 172.96\n",
      "max_test: 140.57\n",
      "min_train: 0.0\n",
      "min_valid: 0.0\n",
      "min_test: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Load test, valid, and train datasets from Phoneme/test_x.npy\n",
    "train = np.load('../Data/Phoneme/train_X.npy')\n",
    "valid = np.load('../Data/Phoneme/valid_X.npy')\n",
    "test = np.load('../Data/Phoneme/test_X.npy')\n",
    "\n",
    "# Find max value in train, valid, and test datasets\n",
    "max_train = np.max(train)\n",
    "max_valid = np.max(valid)\n",
    "max_test = np.max(test)\n",
    "\n",
    "# Find min value in train, valid, and test datasets\n",
    "min_train = np.min(train)\n",
    "min_valid = np.min(valid)\n",
    "min_test = np.min(test)\n",
    "\n",
    "# Find global max and min\n",
    "global_max = max(max_train, max_valid, max_test)\n",
    "global_min = min(min_train, min_valid, min_test)\n",
    "\n",
    "print(\"max_train:\", max_train)\n",
    "print(\"max_valid:\", max_valid)\n",
    "print(\"max_test:\", max_test)\n",
    "\n",
    "print(\"min_train:\", min_train)\n",
    "print(\"min_valid:\", min_valid)\n",
    "print(\"min_test:\", min_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01991d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Num examples, num time steps, num channels)\n",
      "Shape of train dataset: (3315, 217, 11)\n",
      "Shape of valid dataset: (1677, 217, 11)\n",
      "Shape of test dataset: (1676, 217, 11)\n"
     ]
    }
   ],
   "source": [
    "# print shapes of the train dataset\n",
    "print(\"(Num examples, num time steps, num channels)\")\n",
    "print(\"Shape of train dataset:\", train.shape)\n",
    "print(\"Shape of valid dataset:\", valid.shape)\n",
    "print(\"Shape of test dataset:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c94d04",
   "metadata": {},
   "source": [
    "# Reshape data and resave it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1339c921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataset: (3315, 11, 217)\n",
      "Shape of valid dataset: (1677, 11, 217)\n",
      "Shape of test dataset: (1676, 11, 217)\n"
     ]
    }
   ],
   "source": [
    "# Load test, valid, and train datasets from Phoneme/test_x.npy\n",
    "train = np.load('../Data/Phoneme/train_X.npy')\n",
    "valid = np.load('../Data/Phoneme/valid_X.npy')\n",
    "test = np.load('../Data/Phoneme/test_X.npy')\n",
    "\n",
    "# Reshape test_X, test_y and all to be (N, C, T) where N is the number of examples, C is the number of channels, and T is the number of time steps\n",
    "train = np.reshape(train, (train.shape[0], train.shape[2], train.shape[1]))\n",
    "valid = np.reshape(valid, (valid.shape[0], valid.shape[2], valid.shape[1]))\n",
    "test = np.reshape(test, (test.shape[0], test.shape[2], test.shape[1]))\n",
    "\n",
    "print(\"Shape of train dataset:\", train.shape)\n",
    "print(\"Shape of valid dataset:\", valid.shape)\n",
    "print(\"Shape of test dataset:\", test.shape)\n",
    "\n",
    "# Save\n",
    "np.save('../Data/Phoneme/train_X.npy', train)\n",
    "np.save('../Data/Phoneme/valid_X.npy', valid)\n",
    "np.save('../Data/Phoneme/test_X.npy', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341900d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ade69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp_mixer",
   "language": "python",
   "name": "mlp_mixer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
